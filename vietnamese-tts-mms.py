#!/usr/bin/env python3
"""
Vietnamese TTS using Facebook MMS + Gradio
Uses Transformers library - works perfectly on Colab
No binary permissions issues!
"""

import torch
import gradio as gr
import scipy.io.wavfile
import tempfile
import os
from pathlib import Path

# Global variables for model
model = None
tokenizer = None
MODEL_NAME = "facebook/mms-tts-vie"


def load_model():
    """Load MMS Vietnamese TTS model"""
    global model, tokenizer

    if model is not None:
        print("‚úì Model already loaded")
        return

    print(f"üì• Loading {MODEL_NAME}...")

    from transformers import VitsModel, AutoTokenizer

    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = VitsModel.from_pretrained(MODEL_NAME)

    # Move to GPU if available
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)

    print(f"‚úì Model loaded on {device}")


def generate_speech(text):
    """Generate Vietnamese speech from text"""
    if not text or not text.strip():
        return None, "‚ö†Ô∏è Please enter some text"

    try:
        print(f"üé§ Generating: {text[:50]}...")

        # Tokenize input
        inputs = tokenizer(text, return_tensors="pt")

        # Move to same device as model
        device = next(model.parameters()).device
        inputs = {k: v.to(device) for k, v in inputs.items()}

        # Set seed for reproducibility
        torch.manual_seed(42)

        # Generate speech with reduced noise for better word preservation
        with torch.no_grad():
            output = model(
                **inputs,
                noise_scale=0.3,  # Lower = less randomness, fewer skipped words
                noise_scale_duration=0.5  # Lower = more stable durations
            ).waveform

        # Move to CPU and convert to numpy
        waveform = output.cpu().squeeze().numpy()

        # Save to temporary file
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            output_file = tmp.name

        # Write WAV file
        sample_rate = model.config.sampling_rate
        scipy.io.wavfile.write(output_file, rate=sample_rate, data=waveform)

        file_size = os.path.getsize(output_file) / 1024
        print(f"‚úì Generated {file_size:.1f}KB audio")

        return output_file, f"‚úÖ Generated {file_size:.1f}KB audio at {sample_rate}Hz"

    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return None, f"‚ùå Error: {str(e)}"


def create_ui():
    """Create Gradio interface"""

    examples = [
        ["Xin ch√†o! T√¥i l√† tr·ª£ l√Ω gi·ªçng n√≥i ti·∫øng Vi·ªát c·ªßa b·∫°n."],
        ["Vi·ªát Nam l√† m·ªôt qu·ªëc gia ƒë·∫πp v·ªõi l·ªãch s·ª≠ v√† vƒÉn h√≥a phong ph√∫."],
        ["H·ªçc ti·∫øng Vi·ªát r·∫•t th√∫ v·ªã v√† b·ªï √≠ch."],
        ["C√¥ng ngh·ªá tr√≠ tu·ªá nh√¢n t·∫°o ƒëang ph√°t tri·ªÉn nhanh ch√≥ng."],
        ["H√¥m nay tr·ªùi ƒë·∫πp, ch√∫ng ta ƒëi ch∆°i nh√©!"],
        ["T√¥i th√≠ch ƒÉn ph·ªü v√† b√°nh m√¨ v√†o bu·ªïi s√°ng."],
        ["√Çm nh·∫°c Vi·ªát Nam r·∫•t hay v√† ƒëa d·∫°ng."],
        ["Ch√∫ng t√¥i s·∫Ω ƒëi du l·ªãch v√†o m√πa h√® n√†y."],
    ]

    with gr.Blocks(
        title="Vietnamese TTS - Facebook MMS",
        theme=gr.themes.Soft(primary_hue="purple")
    ) as demo:

        gr.Markdown("""
        # üáªüá≥ Vietnamese Text-to-Speech
        ### Facebook MMS Model - Free & High Quality
        """)

        with gr.Row():
            with gr.Column():
                text_input = gr.Textbox(
                    label="Vietnamese Text",
                    placeholder="Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát c·ªßa b·∫°n...",
                    lines=5,
                    value="Xin ch√†o! T√¥i l√† tr·ª£ l√Ω gi·ªçng n√≥i ti·∫øng Vi·ªát c·ªßa b·∫°n."
                )

                with gr.Row():
                    generate_btn = gr.Button("üîä Generate Speech", variant="primary", size="lg")
                    clear_btn = gr.ClearButton([text_input], value="üóëÔ∏è Clear")

                status_output = gr.Textbox(
                    label="Status",
                    interactive=False,
                    show_label=False
                )

            with gr.Column():
                audio_output = gr.Audio(
                    label="Generated Audio",
                    type="filepath",
                    autoplay=True
                )

        gr.Markdown("### üìù Example Texts (click to use)")
        gr.Examples(
            examples=examples,
            inputs=text_input,
            label=None
        )

        device_info = "üéÆ GPU" if torch.cuda.is_available() else "üíª CPU"

        gr.Markdown(f"""
        ---
        **Model**: {MODEL_NAME}
        **Architecture**: VITS (Facebook MMS)
        **Language**: Vietnamese (vi-VN)
        **Device**: {device_info}
        **Quality**: High (16kHz)
        """)

        generate_btn.click(
            fn=generate_speech,
            inputs=text_input,
            outputs=[audio_output, status_output]
        )

    return demo


def main():
    print("=" * 60)
    print("Vietnamese TTS - Facebook MMS")
    print("=" * 60)

    # Check dependencies
    try:
        from transformers import VitsModel, AutoTokenizer
        import scipy
    except ImportError as e:
        print(f"\n‚ùå Missing dependency: {e}")
        print("\nInstall with:")
        print("  pip install transformers torch scipy gradio")
        return

    print("\nüì¶ Loading model...")
    try:
        load_model()
    except Exception as e:
        print(f"\n‚ùå Failed to load model: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\nüöÄ Starting Gradio server...")
    demo = create_ui()
    demo.launch(
        server_name="0.0.0.0",
        share=True,
        show_error=True
    )


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüëã Shutting down...")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
